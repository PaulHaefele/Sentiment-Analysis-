{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fc8e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d539f",
   "metadata": {},
   "source": [
    "# Pre-Processing and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34a254f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom scipy.sparse import hstack\\n\\nimport nltk\\nimport spacy\\nfrom textblob import TextBlob\\n\\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\\n\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nfrom sklearn.model_selection import GridSearchCV\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.svm import SVC\\nfrom sklearn.naive_bayes import MultinomialNB\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom scipy.sparse import hstack\\n\\nimport nltk\\nimport spacy\\nfrom textblob import TextBlob\\n\\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\\n\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nfrom sklearn.model_selection import GridSearchCV\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.svm import SVC\\nfrom sklearn.naive_bayes import MultinomialNB\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f47eb2",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf036b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userRating</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked a adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>it work a expected. I should have sprung for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This think ha worked out great.Had a diff. bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userRating                                         reviewText\n",
       "0         4.0                                         No issues.\n",
       "1         5.0  Purchased this for my device, it worked a adve...\n",
       "2         4.0  it work a expected. I should have sprung for t...\n",
       "3         5.0  This think ha worked out great.Had a diff. bra...\n",
       "4         5.0  Bought it with Retail Packaging, arrived legit..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Load the cleaned data from the CSV file\\ndf = pd.read_csv(\\\"cleaned_data.csv\\\")\\n\\n# Display the first few rows to verify the data\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"# Load the cleaned data from the CSV file\\ndf = pd.read_csv(\\\"cleaned_data.csv\\\")\\n\\n# Display the first few rows to verify the data\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the cleaned data from the CSV file\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbca7f8",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with VADER\n",
    "\n",
    "In this section, we will perform sentiment analysis using the VADER (Valence Aware Dictionary and sEntiment Reasoner) library on the review text. VADER is a lexicon and rule-based sentiment analysis tool specifically designed for social media text.\n",
    "\n",
    "**Why we are doing this:**\n",
    "\n",
    "1. To enrich the dataset: By analyzing the sentiment of reviews, we can extract additional information about the emotional tone of the text, which may be valuable for modeling.\n",
    "\n",
    "2. Feature creation: We will create a new column, 'vader_sentiment', to store the sentiment analysis results for each review. This additional feature can potentially be used in our classification models.\n",
    "\n",
    "Let's proceed with the sentiment analysis using VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcc856f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Intitialize the VADER analyzer\\nanalyzer = SentimentIntensityAnalyzer()\\n\\n# Loop through the User Review Text and apply VADER to each review\\nsentiments = []\\nfor text in df[\\\"reviewText\\\"]:\\n    sentiment = analyzer.polarity_scores(text)\\n    sentiments.append(sentiment[\\\"compound\\\"])\\n\\n# Create new column to store VADER analysis compound results\\ndf[\\\"vader_sentiment\\\"] = sentiments\";\n",
       "                var nbb_formatted_code = \"# Intitialize the VADER analyzer\\nanalyzer = SentimentIntensityAnalyzer()\\n\\n# Loop through the User Review Text and apply VADER to each review\\nsentiments = []\\nfor text in df[\\\"reviewText\\\"]:\\n    sentiment = analyzer.polarity_scores(text)\\n    sentiments.append(sentiment[\\\"compound\\\"])\\n\\n# Create new column to store VADER analysis compound results\\ndf[\\\"vader_sentiment\\\"] = sentiments\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intitialize the VADER analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Loop through the User Review Text and apply VADER to each review\n",
    "sentiments = []\n",
    "for text in df[\"reviewText\"]:\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    sentiments.append(sentiment[\"compound\"])\n",
    "\n",
    "# Create new column to store VADER analysis compound results\n",
    "df[\"vader_sentiment\"] = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2320a0",
   "metadata": {},
   "source": [
    "## Feature Extraction with TF-IDF Vectorization\n",
    "\n",
    "In this section, we'll perform feature extraction using the TF-IDF (Term Frequency-Inverse Document Frequency) vectorization technique. The reason we've chosen TF-IDF over CountVectorizer is that TF-IDF takes into account not only the term frequency (the number of times a word appears in a document) but also the inverse document frequency (how unique or rare a term is across all documents in the dataset). This allows us to emphasize the importance of words for sentiment analysis, especially in differentiating between words that appear frequently across all reviews and those that are more specific to each review's sentiment.\n",
    "\n",
    "TF-IDF vectorization will transform the review text data into numerical features, which we can use for model development. After applying TF-IDF vectorization, we'll concatenate the VADER sentiment analysis results with these TF-IDF features to create a feature matrix for our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b736ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Initialize the TF-IDF vectorizer\\ntfidfvectorizer = TfidfVectorizer()\\n\\n# Fit and transform your text data\\ntfidf_matrix = tfidfvectorizer.fit_transform(df[\\\"reviewText\\\"])\";\n",
       "                var nbb_formatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Initialize the TF-IDF vectorizer\\ntfidfvectorizer = TfidfVectorizer()\\n\\n# Fit and transform your text data\\ntfidf_matrix = tfidfvectorizer.fit_transform(df[\\\"reviewText\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform your text data\n",
    "tfidf_matrix = tfidfvectorizer.fit_transform(df[\"reviewText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e42dc1a",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "In this phase, we'll split the dataset into training and testing subsets to facilitate model development and evaluation.\n",
    "\n",
    "Additionally, we should address the potential class imbalance in the data, with an overwhelming number of 5-star reviews. We can explore methods to balance the dataset to ensure the model's performance isn't skewed by the imbalance.\n",
    "\n",
    "Let's proceed with addressing the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa695a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE\\n\\n# Define X and y to prepare SMOTE and data splitting\\n# Concatenate the VADER sentiment analysis results with the TF-IDF matrix\\nX = hstack((tfidf_matrix, df[\\\"vader_sentiment\\\"].values.reshape(-1, 1)))\\ny = df.userRating\\n\\n# Create a SMOTE object\\nsmote = SMOTE(random_state=42)\\n\\n# Apply SMOTE to balance the dataset\\nX_resampled, y_resampled = smote.fit_resample(X, y)\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE\\n\\n# Define X and y to prepare SMOTE and data splitting\\n# Concatenate the VADER sentiment analysis results with the TF-IDF matrix\\nX = hstack((tfidf_matrix, df[\\\"vader_sentiment\\\"].values.reshape(-1, 1)))\\ny = df.userRating\\n\\n# Create a SMOTE object\\nsmote = SMOTE(random_state=42)\\n\\n# Apply SMOTE to balance the dataset\\nX_resampled, y_resampled = smote.fit_resample(X, y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define X and y to prepare SMOTE and data splitting\n",
    "# Concatenate the VADER sentiment analysis results with the TF-IDF matrix\n",
    "X = hstack((tfidf_matrix, df[\"vader_sentiment\"].values.reshape(-1, 1)))\n",
    "y = df.userRating\n",
    "\n",
    "# Create a SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952be04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_resampled, y_resampled, test_size=0.2, random_state=42\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_resampled, y_resampled, test_size=0.2, random_state=42\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f4458",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Grid Search\n",
    "\n",
    "In this section, we will perform hyperparameter tuning for our selected machine learning models. The process involves systematically searching through a range of hyperparameters to find the combination that results in the best model performance. Grid search is a powerful technique for optimizing models and can lead to improved predictive accuracy.\n",
    "\n",
    "**Why Hyperparameter Tuning?**\n",
    "\n",
    "- Models often have various hyperparameters that can significantly impact their performance.\n",
    "- Finding the optimal set of hyperparameters can improve model accuracy and generalization.\n",
    "\n",
    "**Grid Search Method:**\n",
    "\n",
    "- We will define a range of hyperparameters for each model.\n",
    "- Grid search will systematically explore all possible combinations of hyperparameters.\n",
    "- The process is guided by cross-validation to avoid overfitting.\n",
    "\n",
    "**Selected Models:**\n",
    "\n",
    "We have selected the following models for hyperparameter tuning:\n",
    "\n",
    "1. Random Forest\n",
    "2. Support Vector Machine (SVM)\n",
    "\n",
    "In the subsequent sections, we will perform grid search for each model individually, optimizing their respective hyperparameters.\n",
    "\n",
    "Let's get started with hyperparameter tuning to achieve the best predictive performance for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfb3481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.968247826306168\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Random Forest Grid Search\\n\\nparam_grid = {\\n    \\\"n_estimators\\\": [50, 100, 150, 200],\\n    \\\"max_depth\\\": [10, 20, 30, None],\\n}\\n\\nrf = RandomForestClassifier(random_state=42)\\n\\nrf_cv = GridSearchCV(rf, param_grid, cv=5)\\n\\nrf_cv.fit(X_train, y_train)\\n\\nbest_params = rf_cv.best_params_\\nbest_model = rf_cv.best_estimator_\\n\\nprint(\\\"Best Score:\\\" + str(rf_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(rf_cv.best_params_))\";\n",
       "                var nbb_formatted_code = \"# Random Forest Grid Search\\n\\nparam_grid = {\\n    \\\"n_estimators\\\": [50, 100, 150, 200],\\n    \\\"max_depth\\\": [10, 20, 30, None],\\n}\\n\\nrf = RandomForestClassifier(random_state=42)\\n\\nrf_cv = GridSearchCV(rf, param_grid, cv=5)\\n\\nrf_cv.fit(X_train, y_train)\\n\\nbest_params = rf_cv.best_params_\\nbest_model = rf_cv.best_estimator_\\n\\nprint(\\\"Best Score:\\\" + str(rf_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(rf_cv.best_params_))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest Grid Search\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "best_params = rf_cv.best_params_\n",
    "best_model = rf_cv.best_estimator_\n",
    "\n",
    "print(\"Best Score:\" + str(rf_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332c11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.968247826306168\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"print(\\\"Best Score:\\\" + str(rf_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(rf_cv.best_params_))\";\n",
       "                var nbb_formatted_code = \"print(\\\"Best Score:\\\" + str(rf_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(rf_cv.best_params_))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Best Score:\" + str(rf_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0153a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.9840601887273656\n",
      "Best Parameters: {'C': 10, 'gamma': 1}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# SVM Grid Search\\n\\nparam_grid = {\\n    \\\"C\\\": [0.1, 1, 10, 100],\\n    \\\"gamma\\\": [1,0.1,0.01,0.001],\\n}\\n\\nsvm = SVC(random_state=42)\\n\\nsvm_cv = GridSearchCV(svm, param_grid, cv=3, n_jobs=-1)\\n\\nsvm_cv.fit(X_train, y_train)\\n\\nbest_params = svm_cv.best_params_\\nbest_model = svm_cv.best_estimator_\\n\\nprint(\\\"Best Score:\\\" + str(svm_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(svm_cv.best_params_))\";\n",
       "                var nbb_formatted_code = \"# SVM Grid Search\\n\\nparam_grid = {\\n    \\\"C\\\": [0.1, 1, 10, 100],\\n    \\\"gamma\\\": [1, 0.1, 0.01, 0.001],\\n}\\n\\nsvm = SVC(random_state=42)\\n\\nsvm_cv = GridSearchCV(svm, param_grid, cv=3, n_jobs=-1)\\n\\nsvm_cv.fit(X_train, y_train)\\n\\nbest_params = svm_cv.best_params_\\nbest_model = svm_cv.best_estimator_\\n\\nprint(\\\"Best Score:\\\" + str(svm_cv.best_score_))\\nprint(\\\"Best Parameters: \\\" + str(svm_cv.best_params_))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVM Grid Search\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "svm_cv = GridSearchCV(svm, param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "svm_cv.fit(X_train, y_train)\n",
    "\n",
    "best_params = svm_cv.best_params_\n",
    "best_model = svm_cv.best_estimator_\n",
    "\n",
    "print(\"Best Score:\" + str(svm_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(svm_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9b85a",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In this section, we will build and evaluate different machine learning models to predict user ratings based on the sentiment analysis of review texts. We have selected Logistic Regression, Random Forest, Support Vector Machine (SVM), and Naive Bayes as our primary models.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "1. **Logistic Regression:** Logistic regression is a simple yet effective model for binary and multiclass classification tasks. We have chosen this model because it can work well for sentiment analysis problems, making it a suitable candidate for predicting user ratings.\n",
    "\n",
    "2. **Random Forest:** Random Forest is an ensemble learning method that combines multiple decision trees. It is known for its ability to handle complex relationships within the data, which is essential for sentiment analysis tasks that involve text data.\n",
    "\n",
    "3. **Support Vector Machine (SVM):** SVM is a powerful classification algorithm that works well when data is not linearly separable. With its flexibility in kernel functions, SVM can be adapted for sentiment analysis, making it another strong candidate.\n",
    "\n",
    "### Model Tuning\n",
    "\n",
    "We have performed hyperparameter tuning through Grid Search to find the best set of parameters for our models. These hyperparameters will allow us to optimize the model's performance and enhance our predictions.\n",
    "\n",
    "Let's proceed to the modeling phase and evaluate the performance of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b52d4",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "720e5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      0.99      0.99       786\n",
      "         2.0       1.00      1.00      1.00       768\n",
      "         3.0       0.98      1.00      0.99       813\n",
      "         4.0       0.87      0.91      0.89       771\n",
      "         5.0       0.90      0.83      0.86       783\n",
      "\n",
      "    accuracy                           0.95      3921\n",
      "   macro avg       0.94      0.94      0.94      3921\n",
      "weighted avg       0.94      0.95      0.94      3921\n",
      "\n",
      "Confusion Matrix:\n",
      "[[780   0   1   0   5]\n",
      " [  0 768   0   0   0]\n",
      " [  0   0 812   0   1]\n",
      " [  3   0   3 699  66]\n",
      " [ 12   1  16 107 647]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"regr = LogisticRegression(max_iter=1000)\\nmodel = regr.fit(X_train, y_train)\\n\\n# Make predictions on the test set\\ny_pred = model.predict(X_test)\\n\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\\"Accuracy: {accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, y_pred))\";\n",
       "                var nbb_formatted_code = \"regr = LogisticRegression(max_iter=1000)\\nmodel = regr.fit(X_train, y_train)\\n\\n# Make predictions on the test set\\ny_pred = model.predict(X_test)\\n\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f\\\"Accuracy: {accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regr = LogisticRegression(max_iter=1000)\n",
    "model = regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf1628",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5946346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Create the Random Forest classifier\\nrf_classifier = RandomForestClassifier(max_depth=None, n_estimators=200, random_state=42)\\n\\n# Train the model on the training data\\nrf_classifier.fit(X_train, y_train)\\n\\nrf_y_pred = rf_classifier.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"# Create the Random Forest classifier\\nrf_classifier = RandomForestClassifier(\\n    max_depth=None, n_estimators=200, random_state=42\\n)\\n\\n# Train the model on the training data\\nrf_classifier.fit(X_train, y_train)\\n\\nrf_y_pred = rf_classifier.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    max_depth=None, n_estimators=200, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "rf_y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ca4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.98      0.99       786\n",
      "         2.0       1.00      0.99      0.99       768\n",
      "         3.0       1.00      0.99      1.00       813\n",
      "         4.0       0.97      0.92      0.95       771\n",
      "         5.0       0.90      0.97      0.93       783\n",
      "\n",
      "    accuracy                           0.97      3921\n",
      "   macro avg       0.97      0.97      0.97      3921\n",
      "weighted avg       0.97      0.97      0.97      3921\n",
      "\n",
      "Confusion Matrix:\n",
      "[[773   0   0   0  13]\n",
      " [  0 760   0   0   8]\n",
      " [  0   0 807   0   6]\n",
      " [  0   0   0 711  60]\n",
      " [  4   0   0  21 758]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"rf_accuracy = accuracy_score(y_test, rf_y_pred)\\nprint(f\\\"Accuracy: {rf_accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, rf_y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, rf_y_pred))\";\n",
       "                var nbb_formatted_code = \"rf_accuracy = accuracy_score(y_test, rf_y_pred)\\nprint(f\\\"Accuracy: {rf_accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, rf_y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, rf_y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608f21a",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4977561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"svm_classifier = SVC(C = 10, gamma = 1, random_state=42)\\n\\nsvm_classifier.fit(X_train, y_train)\\n\\nsvm_y_pred = svm_classifier.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"svm_classifier = SVC(C=10, gamma=1, random_state=42)\\n\\nsvm_classifier.fit(X_train, y_train)\\n\\nsvm_y_pred = svm_classifier.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_classifier = SVC(C=10, gamma=1, random_state=42)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "svm_y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a34154",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       786\n",
      "         2.0       1.00      1.00      1.00       768\n",
      "         3.0       1.00      1.00      1.00       813\n",
      "         4.0       1.00      0.98      0.99       771\n",
      "         5.0       0.98      0.99      0.99       783\n",
      "\n",
      "    accuracy                           1.00      3921\n",
      "   macro avg       1.00      1.00      1.00      3921\n",
      "weighted avg       1.00      1.00      1.00      3921\n",
      "\n",
      "Confusion Matrix:\n",
      "[[786   0   0   0   0]\n",
      " [  0 768   0   0   0]\n",
      " [  0   0 813   0   0]\n",
      " [  0   0   0 758  13]\n",
      " [  2   0   1   2 778]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"svm_accuracy = accuracy_score(y_test, svm_y_pred)\\nprint(f\\\"Accuracy: {svm_accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, svm_y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, svm_y_pred))\";\n",
       "                var nbb_formatted_code = \"svm_accuracy = accuracy_score(y_test, svm_y_pred)\\nprint(f\\\"Accuracy: {svm_accuracy:.2f}\\\")\\n\\nprint(\\\"Classification Report:\\\")\\nprint(classification_report(y_test, svm_y_pred))\\n\\nprint(\\\"Confusion Matrix:\\\")\\nprint(confusion_matrix(y_test, svm_y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"Accuracy: {svm_accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d93571",
   "metadata": {},
   "source": [
    "## Cross-Validation to Assess Generalization\n",
    "\n",
    "The SVM and Random Forest models demonstrated impressively high accuracy on the initial test set. To ensure that these models are not overfitting the data and to assess their generalization capabilities, we are conducting cross-validation. Cross-validation allows us to evaluate model performance across multiple different data splits and provides a more comprehensive view of their robustness.\n",
    "\n",
    "This process helps verify that the high accuracy observed is not merely a result of chance and provides a better estimate of the models' performance in real-world scenarios.\n",
    "\n",
    "We will first evaluate the SVM model's performance using cross-validation, followed by a similar assessment of the Random Forest model. This will provide us with a more reliable estimate of how well these models generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17c5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.95740882 0.99642948 0.99821474 0.9979597  0.99821474]\n",
      "Mean Accuracy: 0.9896454985972966\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import cross_val_score\\n\\nsvm_classifier = SVC(C=10, gamma=1, random_state=42)\\n\\nscores = cross_val_score(svm_classifier, X_resampled, y_resampled, cv=5)\\n\\nprint(\\\"Cross-Validation Scores:\\\", scores)\\nprint(\\\"Mean Accuracy:\\\", scores.mean())\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import cross_val_score\\n\\nsvm_classifier = SVC(C=10, gamma=1, random_state=42)\\n\\nscores = cross_val_score(svm_classifier, X_resampled, y_resampled, cv=5)\\n\\nprint(\\\"Cross-Validation Scores:\\\", scores)\\nprint(\\\"Mean Accuracy:\\\", scores.mean())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_classifier = SVC(C=10, gamma=1, random_state=42)\n",
    "\n",
    "scores = cross_val_score(svm_classifier, X_resampled, y_resampled, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e5eb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.89364958 0.99183882 0.993114   0.99260393 0.99285896]\n",
      "Mean Accuracy: 0.9728130578933947\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"rf_classifier = RandomForestClassifier(\\n    max_depth=None, n_estimators=200, random_state=42\\n)\\n\\nscores = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5)\\n\\nprint(\\\"Cross-Validation Scores:\\\", scores)\\nprint(\\\"Mean Accuracy:\\\", scores.mean())\";\n",
       "                var nbb_formatted_code = \"rf_classifier = RandomForestClassifier(\\n    max_depth=None, n_estimators=200, random_state=42\\n)\\n\\nscores = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5)\\n\\nprint(\\\"Cross-Validation Scores:\\\", scores)\\nprint(\\\"Mean Accuracy:\\\", scores.mean())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    max_depth=None, n_estimators=200, random_state=42\n",
    ")\n",
    "\n",
    "scores = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381825da",
   "metadata": {},
   "source": [
    "## Cross-Validation Results\n",
    "\n",
    "To assess the generalization performance of our sentiment analysis models, we conducted cross-validation tests. These tests help evaluate how well our models are likely to perform on unseen data and mitigate concerns about overfitting. \n",
    "\n",
    "The cross-validation results indicate high accuracy and consistency across folds for both the Support Vector Machine (SVM) and Random Forest models. This suggests that these models are likely to generalize well to new data.\n",
    "\n",
    "While these results are promising, it's essential to acknowledge that additional tests and real-world data evaluation may be necessary to further validate the models. We will continue to monitor the models' performance in practice.\n",
    "\n",
    "Now, let's proceed to summarize and discuss the overall findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0db77",
   "metadata": {},
   "source": [
    "## Model Results and Cross-Validation\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "The Logistic Regression model was trained and tested on the dataset. Here are the key results:\n",
    "\n",
    "- **Accuracy:** 95%\n",
    "- **Classification Report:**\n",
    "    |    | Precision | Recall | F1-Score | Support |\n",
    "    |----|-----------|--------|----------|---------|\n",
    "    | 1  | 0.98      | 0.99   | 0.99     | 786     |\n",
    "    | 2  | 1.00      | 1.00   | 1.00     | 768     |\n",
    "    | 3  | 0.98      | 1.00   | 0.99     | 813     |\n",
    "    | 4  | 0.87      | 0.91   | 0.89     | 771     |\n",
    "    | 5  | 0.90      | 0.83   | 0.86     | 783     |\n",
    "- **Confusion Matrix:** Shows the number of correctly and incorrectly classified instances in each class.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "The Random Forest model yielded the following results:\n",
    "\n",
    "- **Accuracy:** 97%\n",
    "- **Classification Report:**\n",
    "    |    | Precision | Recall | F1-Score | Support |\n",
    "    |----|-----------|--------|----------|---------|\n",
    "    | 1  | 0.99      | 0.98   | 0.99     | 786     |\n",
    "    | 2  | 1.00      | 0.99   | 0.99     | 768     |\n",
    "    | 3  | 1.00      | 0.99   | 1.00     | 813     |\n",
    "    | 4  | 0.97      | 0.92   | 0.95     | 771     |\n",
    "    | 5  | 0.90      | 0.97   | 0.93     | 783     |\n",
    "- **Confusion Matrix:** Demonstrates the model's ability to classify data into different categories effectively.\n",
    "\n",
    "### Support Vector Machine (SVM)\n",
    "\n",
    "The SVM model demonstrated impressive results:\n",
    "\n",
    "- **Accuracy:** 100%\n",
    "- **Classification Report:**\n",
    "    |    | Precision | Recall | F1-Score | Support |\n",
    "    |----|-----------|--------|----------|---------|\n",
    "    | 1  | 1.00      | 1.00   | 1.00     | 786     |\n",
    "    | 2  | 1.00      | 1.00   | 1.00     | 768     |\n",
    "    | 3  | 1.00      | 1.00   | 1.00     | 813     |\n",
    "    | 4  | 1.00      | 0.98   | 0.99     | 771     |\n",
    "    | 5  | 0.98      | 0.99   | 0.99     | 783     |\n",
    "- **Confusion Matrix:** Indicates a near-perfect classification performance.\n",
    "\n",
    "### Cross-Validation Results\n",
    "\n",
    "Both Logistic Regression and Random Forest were subjected to cross-validation to evaluate their generalization performance:\n",
    "\n",
    "- Logistic Regression Cross-Validation Mean Accuracy: 98.97%\n",
    "- Random Forest Cross-Validation Mean Accuracy: 97.28%\n",
    "\n",
    "These high mean accuracies suggest that the models are consistent in their performance across different subsets of the data, indicating robustness and reliability.\n",
    "\n",
    "Please note that the SVM model achieved extremely high accuracy and might warrant further investigation to ensure there is no overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883995e3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this sentiment analysis project, we developed and evaluated three different models to predict user ratings based on product reviews. We utilized logistic regression, Support Vector Machine (SVM), and Random Forest models. The primary goal was to assess their performance in accurately classifying user ratings from 1 to 5 based on review text.\n",
    "\n",
    "Our models demonstrated promising results with high accuracy in classifying user ratings. The SVM model, in particular, achieved an impressive accuracy of 99%, followed closely by the Random Forest model at 97%. Logistic regression also showed strong performance, achieving an accuracy of 95%. These high accuracy scores are encouraging, indicating the potential of these models for real-world sentiment analysis tasks.\n",
    "\n",
    "Despite these favorable results, there is still room for improvement and further evaluation. Future work could focus on the following areas:\n",
    "- **Larger Datasets:** Expanding the dataset with a more extensive and diverse collection of reviews could enhance the models' generalization capabilities.\n",
    "- **Hyperparameter Tuning:** Further fine-tuning of hyperparameters could potentially improve the models' performance and robustness.\n",
    "- **Real-world Testing:** Evaluating the models with real-world user reviews and monitoring their performance in production environments is essential to ensure their effectiveness.\n",
    "\n",
    "In conclusion, our sentiment analysis models have shown strong potential for predicting user ratings based on product reviews. However, ongoing refinement and testing are necessary to achieve the highest level of accuracy and reliability in sentiment analysis tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
